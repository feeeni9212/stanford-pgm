
1
00:00:00,000 --> 00:00:04,052
Our final big module in this course is
that of learning a probabilistic graphical

2
00:00:04,052 --> 00:00:09,010
model from data. Before we delve into the
details of a learning, a specific learning

3
00:00:09,010 --> 00:00:13,035
algorithm, let's think about some of the
reasons why we might want to learn a

4
00:00:13,035 --> 00:00:17,083
probabilistic graphical model from data,
some of the different scenarios in which

5
00:00:17,083 --> 00:00:22,041
this learning problem might arise and how
we might go about evaluating the results

6
00:00:22,041 --> 00:00:27,078
of our learning algorithm. So the setup
here is that we assume that we have some

7
00:00:27,078 --> 00:00:32,087
kind of true distribution, which is
typically denoted by P<i>. And in many</i>

8
00:00:32,087 --> 00:00:38,040
cases, although not always, we might
assume that P is actually generated from

9
00:00:38,040 --> 00:00:44,000
a probabilistic graphical model, M<i>. And
that assumption allows us to talk about</i>

10
00:00:44,000 --> 00:00:49,039
the differences between a learned model
and the ground truth model, M that

11
00:00:49,039 --> 00:00:58,007
generated, the distribution. Now. We're
assuming that from this distribution P<i>,</i>

12
00:00:58,007 --> 00:01:05,050
we get a data set, D, of instances
d1 up to dM. And we're assuming that those

13
00:01:05,050 --> 00:01:11,054
are sampled from distribution P<i>. Now,
in addition to the data, we may or may not</i>

14
00:01:11,054 --> 00:01:16,035
have some amount of domain expertise that
allows us to put in some prior knowledge

15
00:01:16,035 --> 00:01:20,093
into the model. And in fact, the ability
to put in prior knowledge is one of the

16
00:01:20,093 --> 00:01:25,091
strengths of probabilistic graphical model
learning as compared to a variety of other

17
00:01:25,091 --> 00:01:30,063
learning algorithms where this is not
always quite as easily done. So combining

18
00:01:30,063 --> 00:01:36,024
elicitation from an expert and learning,
what we end up with is a network that we

19
00:01:36,024 --> 00:01:41,078
can then, look at and use for different
purposes. So to make this a little bit

20
00:01:41,078 --> 00:01:46,097
more concrete, let's look at the,
different scenarios in the context of a

21
00:01:46,097 --> 00:01:52,064
Bayesian network. The issues in a Markov
network look, fairly identical. So in the

22
00:01:52,064 --> 00:01:58,017
case of known structure and complete data,
we have a network which we assume to be

23
00:01:58,017 --> 00:02:04,047
true. We have input data which is nice and
clean. We see that all the variables have

24
00:02:04,047 --> 00:02:11,052
values in every single instance. And our
goal is to produce. This set of CPDs, for

25
00:02:11,052 --> 00:02:18,034
the network. In the case of unknown
structure in the complete data, we have

26
00:02:18,034 --> 00:02:26,044
the same type of datasets, but notice that
now the initial network has no edges in it

27
00:02:26,044 --> 00:02:33,051
and we now need to infer the edge connectivity as well as the CPDs. Incomplete

28
00:02:33,051 --> 00:02:40,035
data arises when, notice that here we have
some of the variables are not observed in

29
00:02:40,035 --> 00:02:46,095
the training data. And as we'll this can
actually complicate the learning problem

30
00:02:46,095 --> 00:02:53,095
quite considerably. And finally, the
unknown structure, incomplete data. Now in

31
00:02:53,095 --> 00:03:00,010
the latent variable case notice that we
have a situation where we know about three

32
00:03:00,010 --> 00:03:05,088
of the variables X1, X2 and Y but our
final model has in addition to X1, X2 and

33
00:03:05,088 --> 00:03:12,011
Y an additional latent variable H that we
didn't even know about, it might have been

34
00:03:12,011 --> 00:03:18,019
here but we didn't observe any of the
values for it. We didn't even know of its

35
00:03:18,019 --> 00:03:24,026
existent and we want to learn a model that
involves not only X1, X2 and Y but also

36
00:03:24,026 --> 00:03:31,014
the variable H. So, now let's think about
the reasons why we might want to learn a

37
00:03:31,014 --> 00:03:35,076
probabilistic graphical model. And, the
most obvious one is that we want a model

38
00:03:35,076 --> 00:03:40,043
that we can use in the same way that we
would use one that we elicited by hand to

39
00:03:40,043 --> 00:03:44,099
just answer probabilistic queries whether
conditional probability queries or map

40
00:03:44,099 --> 00:03:49,043
queries, about new instances that we
haven't seen before. Now, introducing

41
00:03:49,043 --> 00:03:55,049
concepts that we'll study in a more detail
a little bit later on, the simplest

42
00:03:55,049 --> 00:04:01,033
possible metric that we might envision,
for training a PGM is basically, how

43
00:04:01,033 --> 00:04:07,086
probable are the instances that we've seen
relative to a given model? So, this metric

44
00:04:07,086 --> 00:04:14,015
is called training set likelihood and
it's formalized as the following, it's the

45
00:04:14,015 --> 00:04:20,075
probability of the data that we've seen,
our data set D. Relative to a given model M.

46
00:04:20,075 --> 00:04:25,094
And the intuition behind this is, that if
a model makes the data more likely, it,

47
00:04:25,094 --> 00:04:31,018
that it was more likely to have generated
this data set then it's a pretty good

48
00:04:31,018 --> 00:04:37,002
model or pretty good assumption about the
process that generated our data. And, in

49
00:04:37,002 --> 00:04:43,082
this in just opening up this definition
this just turns into the product over,

50
00:04:44,007 --> 00:04:51,054
over instances M of the probability of the
individual instances given the model given

51
00:04:51,054 --> 00:04:58,042
candidate model M. And this is assuming
that the instances are, independent and

52
00:04:58,042 --> 00:05:04,080
identically distributed from the model M.
So, one important notion that will

53
00:05:04,080 --> 00:05:10,031
accompany us throughout this discussion is
that while training set likelihood seems

54
00:05:10,031 --> 00:05:15,081
intuitively like a pretty good, surrogate
for a pretty good scoring function for

55
00:05:15,081 --> 00:05:21,006
picking a model, it isn't what we actually
care about. Because what we really care

56
00:05:21,006 --> 00:05:25,071
about is new data. Not the data that we
got before. We care about making

57
00:05:25,071 --> 00:05:31,024
conclusions about data that we haven't
seen. And so what we really want to do is

58
00:05:31,024 --> 00:05:37,040
evaluate our model on a separate test set
and you've all already seen the notion of

59
00:05:37,040 --> 00:05:43,026
test set in concept of other learning
problems and the same the same idea is

60
00:05:43,026 --> 00:05:49,013
fundamental here in PGM as well is that
our evaluation really should care about

61
00:05:49,013 --> 00:05:55,015
not the original data set D but
rather a new data set D prime

62
00:05:55,015 --> 00:06:00,036
which gives us a surrogate for what's
called generalization performance.

63
00:06:00,036 --> 00:06:12,003
[sound]. [sound]. A related, but somewhat
different variant on the notion of,

64
00:06:12,003 --> 00:06:17,063
[inaudible], on the learning task that you
might want the PGM to perform, is when we

65
00:06:17,063 --> 00:06:23,049
have a specific prediction problem that we
care about. So, for example, we might so

66
00:06:23,049 --> 00:06:28,028
where we specifically care about
predicting a particular set of target

67
00:06:28,028 --> 00:06:33,007
variables Y from a set of observed
variables X. And we've seen multiple

68
00:06:33,007 --> 00:06:37,099
examples of this such as image
segmentation, where we have, for example,

69
00:06:37,099 --> 00:06:43,050
X being the pixels in the image, and Y
being the predictive. Class labels. Speech

70
00:06:43,050 --> 00:06:49,065
recognition is another such example, where
we have an acoustic signal as X, and a

71
00:06:49,065 --> 00:06:57,019
sequence of phonemes as Y. So all of these
are, are cases where we have a particular

72
00:06:57,019 --> 00:07:03,004
prediction task. Now. Although, in this
case, we often care about a specialized

73
00:07:03,004 --> 00:07:08,014
objective. So, for example, pixel-level segmentation accuracy, in the

74
00:07:08,014 --> 00:07:13,059
context of the image segmentation. Or in
the context of speech recognition, might

75
00:07:13,059 --> 00:07:19,010
care about the word accuracy rate. Even
though that's often the case, it turns out

76
00:07:19,010 --> 00:07:24,081
that, in many cases, it's convenient for,
for algorithmic and mathematical purposes,

77
00:07:24,081 --> 00:07:29,075
to select our model to optimize the same
notion of either likelihood. Or

78
00:07:29,075 --> 00:07:35,078
conditional likelihood, where we try and
predict, where we're computing the

79
00:07:35,078 --> 00:07:41,071
probability of the Y's given the X's. And
although that. Likelihood is not always a

80
00:07:41,071 --> 00:07:45,072
perfect surrogate for the objective that,
the specialized objective, that we

81
00:07:45,072 --> 00:07:50,000
actually care about, it turns out to be
mathematically convenient, and that's why

82
00:07:50,000 --> 00:07:55,073
it's often done. However, it's important
to evaluate the model performance, on the

83
00:07:55,073 --> 00:08:01,069
true objective over test data as opposed
to just use likelihood as in the

84
00:08:01,069 --> 00:08:07,051
evaluation of how successful our learning
algorithm was. A third setting where we

85
00:08:07,051 --> 00:08:12,031
might want to use PGM learning is actually
qualitatively quite different. In this

86
00:08:12,031 --> 00:08:17,000
case, we might not care about using the
model for any particular inference task

87
00:08:17,000 --> 00:08:21,056
but rather we hear about inferring the
structure itself. That is, what we care

88
00:08:21,056 --> 00:08:26,036
about is knowledge discovery, or structure
discovery, where our goal is to try and

89
00:08:26,036 --> 00:08:31,037
get as close as possible to the generating
model, M star. Using PGM learning for this

90
00:08:31,037 --> 00:08:36,023
task might help us distinguish between
direct and indirect dependencies. So if we

91
00:08:36,023 --> 00:08:40,079
see a correlation between X and Y in the
data, we want to infer whether that

92
00:08:40,079 --> 00:08:45,029
corresponds to a direct probabilistic
interaction between them, or something

93
00:08:45,029 --> 00:08:49,085
that, proceeds via third variable Z, for
example. In some cases, when we are

94
00:08:49,085 --> 00:08:54,065
learning a Bayesian network, we might be
able to infer the directionality of the

95
00:08:54,065 --> 00:08:59,031
edges, and thereby, get some intuition
regarding causality. And in other cases

96
00:08:59,031 --> 00:09:04,006
when we learn models with latent
variables, the existence of those latent

97
00:09:04,006 --> 00:09:09,006
variables, their location and often the
way in which the values of the latent

98
00:09:09,006 --> 00:09:14,000
variables get assigned to different
instances, gives us a lot of information

99
00:09:14,000 --> 00:09:20,023
about the structure of the domain. In many
cases although not always when we, when we

100
00:09:20,023 --> 00:09:26,090
solve this learning problem by training
using the same ideas that use a likelihood

101
00:09:26,090 --> 00:09:32,049
based objective for training. Now we know
that, that is not a particularly good

102
00:09:32,049 --> 00:09:37,042
surrogate for structural accuracy but from
a mathematical and algorithmic

103
00:09:37,042 --> 00:09:42,055
perspective, it's a very convenient
optimization objective. And therefore it's

104
00:09:42,055 --> 00:09:48,012
often used in practice although there are
also other ideas out there. However, it's

105
00:09:48,012 --> 00:09:53,074
important not to use likelihood even
likelihood of the test set as the sole

106
00:09:53,074 --> 00:09:58,092
objective for evaluating model
performance. And in many cases, as we'll

107
00:09:58,092 --> 00:10:04,054
see in the context of some examples, the
evaluation here needs to be done by

108
00:10:04,054 --> 00:10:10,024
comparing to whatever limited prior
knowledge we have about the model M star.

109
00:10:10,024 --> 00:10:16,060
So we can compare prior knowledge that was
not given to the algorithm and see whether

110
00:10:16,060 --> 00:10:22,050
the algorithm was able to adequately
reconstruct this. Now, we talked earlier

111
00:10:22,050 --> 00:10:29,087
in this module about the fact that, that
the training likelihood tends to over fit

112
00:10:29,087 --> 00:10:36,054
the model and that in fact is a general
observation, that when you select the

113
00:10:36,054 --> 00:10:43,013
model M to optimize the training set
likelihood, then that tends to over fit

114
00:10:43,013 --> 00:10:49,098
badly to statistical noise random
fluctuations that happen when we generate

115
00:10:49,098 --> 00:10:56,052
our training sets. That happens in several
different ways. It happens, by over

116
00:10:56,052 --> 00:11:02,047
fitting at the level of parameters. So
where the parameters fit random noise in

117
00:11:02,047 --> 00:11:09,008
the training data. And that can be avoided
by the use of regularization, or parameter

118
00:11:09,008 --> 00:11:15,045
priors over the parameters. And we'll see
how that gets done. It also happens when

119
00:11:15,045 --> 00:11:19,070
we over fit the structure. And
specifically, one can show that if we

120
00:11:19,070 --> 00:11:25,004
optimize the training set likelihood, then
complex structures always win. That is, we

121
00:11:25,004 --> 00:11:30,038
would always prefer the most complicated
structure that our model allows. And so if

122
00:11:30,038 --> 00:11:35,066
we're training, if we're trying to fit
structure, it's important to either bound

123
00:11:35,066 --> 00:11:40,062
the model complexity, or penalize the
model complexity, so that we don't learn

124
00:11:40,062 --> 00:11:45,064
models that are just ridiculously
complicated for no good reason. Now all of

125
00:11:45,064 --> 00:11:51,062
these different choices that we've talked
about are called hyper-parameters. So

126
00:11:51,062 --> 00:11:57,098
hyper-parameters include things like the
parameters priors or the regularization.

127
00:11:57,098 --> 00:12:03,001
Over parameters, the strength of the
regularization. If we're doing complexity,

128
00:12:03,021 --> 00:12:08,031
bounds, or complexity penalties, that's
another hyperparameter. All of these are

129
00:12:08,031 --> 00:12:13,002
things that we need to pick before we
could actually apply our learning

130
00:12:13,002 --> 00:12:17,086
algorithm. And so how does that happen?
Well, we need to figure out a way to

131
00:12:17,086 --> 00:12:23,009
select that. And it turns out that, that
decision makes a huge difference, in many

132
00:12:23,009 --> 00:12:27,086
cases, to the performance of our learning
algorithm. And so how do we fit these

133
00:12:27,086 --> 00:12:32,022
hyper-parameters? Well one obvious choice
is to put them on the training set. A few

134
00:12:32,022 --> 00:12:36,037
seconds of thought often convinced us
that, that is a terrible idea because we

135
00:12:36,037 --> 00:12:40,073
just talked about the fact that on the
training set the optimal thing to do is to

136
00:12:40,073 --> 00:12:45,020
have maximum complexity. And so if we put
these hyper parameters on the training set

137
00:12:45,020 --> 00:12:49,027
they're going to effectively become
totally vacuous. Another obvious

138
00:12:49,027 --> 00:12:54,088
choice is to pick them on the test set.
That turns out to be another terrible idea

139
00:12:54,088 --> 00:13:00,050
because that basically makes us look over,
makes our performance overly optimistic

140
00:13:00,050 --> 00:13:05,098
because we picked these very important
parameters so as to optimize performance

141
00:13:05,098 --> 00:13:11,064
on the test set. So training set is bad.
Test is bad. And so the correct strategy

142
00:13:11,064 --> 00:13:17,085
is to use what's called a validation set.
Which is a set that is separate from both

143
00:13:17,085 --> 00:13:23,099
our training set on the one hand and our
test set on the other. A variance on this

144
00:13:23,099 --> 00:13:29,078
is to use what's called cross validation
on. The training set, where we split the

145
00:13:29,078 --> 00:13:35,061
training set, iteratively into a training
and a validation component and use that to

146
00:13:35,061 --> 00:13:41,036
pick hyper parameters. And these are all
concepts that you've seen before in the

147
00:13:41,036 --> 00:13:47,057
context of other learning algorithms, and
they're equally important here. [sound]

148
00:13:47,057 --> 00:13:52,070
Finally, let's talk about why you might,
why and when you might want to use PGM

149
00:13:52,070 --> 00:13:58,074
learning as opposed to a generic machine
learning algorithm. Pgm learning is

150
00:13:58,074 --> 00:14:03,069
particularly useful when what we're trying
to do is make predictions, not over a

151
00:14:03,069 --> 00:14:08,082
single output variable, such as a binary
outcome like a positive class or a

152
00:14:08,082 --> 00:14:13,046
negative class. But rather, we're trying
to make predictions over structured

153
00:14:13,046 --> 00:14:18,035
objects. For example, labeling entire
sequences as in when we're trying to do

154
00:14:18,053 --> 00:14:22,065
For example, sequence labeling and, and,
and speech recognition or in natural

155
00:14:22,065 --> 00:14:26,099
language processing or when we're trying
to label entire graphs. For example, in

156
00:14:26,099 --> 00:14:31,021
the case of image segmentation where we
have, there's a grid of pixels and we're

157
00:14:31,021 --> 00:14:35,098
trying to label all the pixels simultan,
simultaneously. This allows us to exploit

158
00:14:35,098 --> 00:14:41,049
correlations between multiple predicted
variables often giving us significant

159
00:14:41,049 --> 00:14:47,026
improvements to performance. A second
reason to use PGM learning, is it allows

160
00:14:47,026 --> 00:14:53,079
us to incorporate prior knowledge into our
model in a way that many other algorithms

161
00:14:53,079 --> 00:14:58,050
have a bit of a difficulty in, in
allowing. And finally, this is

162
00:14:58,050 --> 00:15:04,018
particularly useful when we're trying to
learn a single model. Single state PGM

163
00:15:04,018 --> 00:15:08,091
model for multiple different tasks.
Whereas traditional learning algorithms

164
00:15:08,091 --> 00:15:14,014
you learn a particular x y mapping, here
you can learn a single graphical model and

165
00:15:14,014 --> 00:15:19,012
use it in multiple different ways for
answering different kinds of queries. And

166
00:15:19,012 --> 00:15:24,061
finally the idea of using learning for
knowledge discovery is useful in other is

167
00:15:24,061 --> 00:15:29,053
also possible in the context of other
learning algorithms but is particularly

168
00:15:29,053 --> 00:15:34,013
useful in the context of PGMs because the
form of the knowledge is often

169
00:15:34,013 --> 00:15:35,065
particularity intuitive.
